\section{Related work}\label{sec:related}
Understanding which hypothesis classes can be privately learned is an area of vibrant research and was started in the context of Valiant's~\Gls{pac} learning model~\citep{valiant1984theory}. 
A hypothesis class \(\cH\) is considered~\Gls{pac}-learnable if there exists an algorithm \(\alg\), which can utilize a polynomial-sized\footnote{The term `polynomial-sized' refers to a sample size that is polynomial in the PAC parameters, including the error rate, confidence level, size of the hypothesis class, and the dimensionality of the input space.}, independent, and identically distributed (i.i.d.) sample \(D\) from any data distribution to produce a hypothesis \(h\in\cH\) that achieves a low classification error with high probability on that distribution. In the context of DP-PAC learning, as defined by~\citet{kasiviswanathan2011can}, the learner \(\alg\) must also satisfy~\Gls{dp} constraint with respect to the sample \(D\). The overarching objective in this research domain is to find a clear criterion for the private learnability of hypothesis classes, analogous to the way learnability has been characterized in non-private settingsâ€”through the Vapnik-Chervonenkis (VC) dimension for offline learning~\citep{blumer1989learnability} and the Littlestone dimension for online learning~\citep{littlestone1988learning,ben2009agnostic}.

\citet{kasiviswanathan2011can} started this line of research by showing that the sample complexity of~\Gls{dp}-\Gls{pac} learning a hypothesis class  \(\cH\) is~\(\bigO{\log\br{\abs{\cH}
}}\).~\citet{beimel2014bounds} showed that the VC dimension does not dictate the sample complexity for proper pure~\Gls{dp}-\Gls{pac} learning of the \(\point_N\) class. However, they showed that if the setting is relaxed to improper learning then this sample complexity can be improved, thus showing a separation between proper and improper learning, something that is absent in the non-private~\Gls{pac} model.~\citet{beimel2013characterizing} sharpened this result by constructing a new complexity measure called~\emph{probabilistic representation dimension} and proving that this measure characterises improper pure~\Gls{dp} exactly.

 By leveraging advanced tools from communication complexity theory, they refined the understanding of the probabilistic representation dimension and demonstrated that the sample complexity for learning a notably simple hypothesis class, denoted as \(\line_p\), under approximate improper DP-PAC conditions, is significantly lower than the corresponding lower bound established for pure contexts.

Relaxing the notion of pure~\Gls{dp} to approximate~\Gls{dp},~\citet{beimel2013private} showed that the sample complexity for proper approximate~\Gls{dp}-\Gls{pac} learning can be significantly lower than proper~pure~\Gls{dp}-\Gls{pac} learning, thereby showing a separation between pure and approximate~\Gls{dp} in the context of proper~\Gls{dp}-\Gls{pac} learning. The inquiry into whether a similar discrepancy exists in improper DP-PAC learning was resolved by~\citet{feldman2014sample} who proved a separation between pure and approximate~\Gls{dp} in the improper~\Gls{dp}-\Gls{pac} learning model. To do this, they first proved a sharper characterisation of the probabilistic representation dimension using concepts from communication complexity. Then, they showed that the sample complexity for learning a notably simple hypothesis class, denoted as \(\line_p\), under approximate improper~\Gls{dp}-\Gls{pac} conditions, is significantly lower than the corresponding lower bound established for pure~\Gls{dp}.

 ~\citet{feldman2014sample} were also the first to obtain lower bounds for~\Gls{dp}-\Gls{pac} learning that grows as \(\Omega\br{\ldim{\cH}}\), albeit limited to the pure~\Gls{dp} setting.~\citet{alon2019private} showed that it is possible to obtain a lower bound for approximate~\Gls{dp} that grows as \(\Omega\br{\log^*\br{\ldim{\cH}}}\) thus marking a clear distinction between non-private and approximate \Gls{dp}-\Gls{pac} learning. This finding illustrated that DP-PAC learning's complexity could align with that of online learning, which is similarly governed by the Littlestone dimension. In a series of subsequent works, see~\cite{alon2022private, ghazi2021sample}, a surprising connection was established between private offline learning and non-private online learning. In particular, classes that are privately offline learnable are precisely those with finite Littlestone dimension.

This naturally highlights a similar question of private online learning, in particular whether~\Gls{dp} further limits which classes are learnable in the~\Gls{dp}-Online learning model.~\citet{golowich2021littlestone} provided an algorithm, called~\Gls{dpsoa}, which has expected number of mistakes growing as~\(O(2^{2^{\ldimop}} \log T)\). Interestingly, unlike~\Gls{soa} in the non-private online setting,~\Gls{dpsoa}'s mistake count increases with number of steps \(T\) in the online game. When considering adaptive adversaries, the upper bound on mistakes escalates to \(\bigO{\sqrt{T}}\). Under a slightly weaker definition of~\Gls{dp}, known as Challenge-DP, where the privacy adversary only sees the predictions and not the whole predictor function,~\citet{kaplan2023black} obtained an upper bound of \(\bigO{\log^2\br{T}}\) for both adaptive and oblivious adversaries. However, it is not clear from these works, whether the dependence on \(T\) is unavoidable. A related setting is that of~\emph{continual observation under~\Gls{dp}} where such a dependence is indeed unavoidable under the pure~\Gls{dp} model. However, the results from continual observation do not immediately transfer to online learning as discussed in~\Cref{sec:continual}.
