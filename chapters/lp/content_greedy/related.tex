\section{Related Work}\label{sec:related work}
\paragraph*{\textbf{Worst-case analysis of $\greedy$}}
Perhaps the most well-known algorithm for solving $\hs$, or equivalently $\mvch$, is the greedy algorithm of Lovász~\cite{lovasz1975ratio}, with runtime complexity $O(mn^2)$. This algorithm, which constructs a cover by sequentially adding elements of the ground set which hit the largest number of remaining subsets, was initially studied by Lovász \cite{lovasz1975ratio} and Johnson \cite{johnson1973approximation} independently, for deterministic hypergraphs. Lovász analyses the greedy algorithm to obtain an upper bound on the $\hs$ integrality gap of $1+\log \dmax$. Slavik \cite{slavik1996tight} developed the tightest known approximation lower bound for $\greedy$, constructing an instance where $\greedy$ finds coverings at least $\log{m}$ times as large as the minimum one. Importantly, Feige \cite{feige1998threshold} proved that an approximation ratio of $(1 - \epsilon) \log{m}$ is not achievable in polynomial time for any $\epsilon > 0$ unless \(\mathit{NP} \subset \mathit{TIME}[n^{O(\log \log n)}]\), certifying $\greedy$ as the best possible polynomial-time approximation algorithm for set cover in the worst-case. 
\paragraph*{\textbf{Random $\hs$}}
Little is known about the typical performance of polynomial-time algorithms on random instances of $\hs$. Closing this gap is important from a theoretical standpoint and for applications in combinatorial inference. A prime example of this is found in \emph{group testing}, a classical inference problem where one aims to identify a small subset of defective items within a large population by conducting the smallest number of pooled tests, with applications ranging from the analysis of communication protocols \cite{fernandez2013unbounded} to DNA sequencing \cite{erlich2015biological} and search problems \cite{du2000combinatorial}. In \cite{iliopoulos2021group}, Iliopulos and Zadik consider the smallest hitting set as an estimator in the setting of the group testing problem, referring to it as the \emph{Smallest Satisfying Set} estimator. In particular, they provide extensive empirical evidence supporting the claim that the class of instances of the random hitting set problem induced by non-adaptive group testing is tractably solvable by computers. 
%
\paragraph*{\textbf{Insights from Statistical Physics}}
The analysis of a random instance of $\hs$ appears in the work of M\'ezard and Tarzia and relies on nonrigorous techniques from statistical physics \cite{mezard2007statistical}. This work considers regular uniform hypergraphs, where the degree of vertices and the size of edges are fixed and assumed to be constant. Depending on these values, they evidence sharp transitions between three different phases, the so-called replica symmetry, 1-replica symmetry breaking, and full replica symmetry breaking phases, which characterize the complexity of the optimization landscape for this problem in the average case setting. 
%
\paragraph*{\textbf{Fixed $p$ regime}}
Another instance was studied by Telelis and Zissimopoulos \cite{telelis2005absolute} in the setting of random Bernoulli hypergraphs, where elements belong to subsets independently with \emph{fixed} probability $p\in(0,1)$. Their analysis concerns the asymptotic regime where the size $n$ of the ground set scales to infinity. In this setting, they study the average-case performance of a simple deterministic algorithm which approximates random $\hs$ within an \textit{additive} error term at most $o(\log m)$ almost everywhere. This gives an improvement over Lovász's argument in~\cite{lovasz1975ratio} which provides a multiplicative bound. 
However, the analysis in~\cite{telelis2005absolute} does not capture the case of sparse hypergraphs, i.e., when $p \to 0$ as $n \to \infty$. The analysis in~\cite{telelis2005absolute} also does not prove guarantees for the $\greedy$ algorithm in the chosen parameter regime. 
\paragraph*{\textbf{Related problem formulations}}
We bring to the reader’s attention a more recent line of work \cite{borst2022gaussian, borst2022integrality}, where the authors obtain bounds on (additive) integrality gaps between the value of a random integer program $\max \c^T \x, \A\x \leq \b, \x \in \left\{0,1\right\}^n$ with $m$ constraints and that of its linear programming relaxation for a wide range of distributions on $(\A,\b,\c)$, holding w.h.p. as $n\rightarrow \infty$. These include the case where the entries of $\A$ are uniformly distributed on an integer interval consisting of at least three elements and where the columns of $\A$ are distributed according to an isotropic logconcave distribution. 
However, these fail to capture the setting where $\A$ is sparse with entries in $\left\{0,1\right\}$, which is of interest for $\hs$.